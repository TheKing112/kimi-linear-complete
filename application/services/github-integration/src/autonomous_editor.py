"""
Autonomous Repository Editor
- Analysiert Prompt
- Erstellt Plan
- Implementiert Ã„nderungen
- Erstellt PR
- Integriert mit Cognee Memory fÃ¼r Kontext
- ðŸ†” UUID-Branch-Namen
- ðŸ”— URL-Validierung
- â±ï¸ Timeout-Handling & Latency-Tracking
"""

import os
import re
import json
import uuid
import time
import asyncio
import logging
from typing import Dict, List, Any, Optional
from pathlib import Path
from datetime import datetime

logger = logging.getLogger("autonomous-editor")

class ConflictError(Exception):
    """Repository wird bereits bearbeitet"""
    pass

class TimeoutError(Exception):
    """Operation timed out"""
    pass

class AutonomousEditor:
    def __init__(self, github_url: str, redis_client: 'RedisClient', timeout: int = 30):
        # ðŸ†” UUID-Branch-Namen - Setup
        self.timeout = timeout
        self.latency_tracker = {}
        
        # ðŸ”— URL-Validierung in __init__
        self._validate_github_url(github_url)
        self.github_url = github_url
        
        # Redis-Client mit Timeout-Handling
        self.redis_client = redis_client
        
        # Bestehende Konfiguration
        self.kimi_url = os.getenv("KIMI_LINEAR_URL", "http://kimi-linear:8003")
        self.cognee_url = os.getenv("COGNEE_URL", "http://cognee:8001")
        self.require_approval = os.getenv("AUTONOMOUS_REQUIRE_APPROVAL", "true").lower() == "true"
        self.create_branch = os.getenv("AUTONOMOUS_CREATE_BRANCH", "true").lower() == "true"
        self.max_tokens = int(os.getenv("AUTONOMOUS_MAX_TOKENS", "4096"))
        
    def _validate_github_url(self, url: str) -> bool:
        """ðŸ”— URL-Validierung mit verbessertem Pattern"""
        pattern = r"^https://github\.com/[a-zA-Z0-9-_.]+/[a-zA-Z0-9-_.]+/?$"
        if not re.match(pattern, url):
            raise ValueError(f"UngÃ¼ltige GitHub URL: {url}. Format: https://github.com/owner/repo")
        return True
    
    def create_implementation_plan(self, analysis: Dict[str, Any], risk_enum: Any) -> Dict[str, Any]:
        """Erstelle detaillierten Plan fÃ¼r die Ã„nderungen mit ðŸ†” UUID-Branch-Namen"""
        
        changes = []
        for file_change in analysis["required_changes"]:
            changes.append({
                "file_path": file_change["file"],
                "action": file_change["action"],  # modify, create, delete
                "description": file_change["description"],
                "code_template": file_change.get("template", "")
            })
        
        # ðŸ†” UUID-Branch-Namen-Generierung
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        unique_id = uuid.uuid4().hex[:8]
        
        plan = {
            "branch_name": f"autonomous/{risk_enum.value}-{unique_id}-{timestamp}",
            "base_branch": "main",
            "changes": changes,
            "commit_message": f"[autonomous] {analysis['user_intent'][:50]}...",
            "risk_level": analysis["risk_level"],
            "auto_merge": False  # IMMER manuelles Review
        }
        
        return plan

    async def process_autonomous_request(
        self, 
        prompt: str, 
        repo_url: str, 
        user_id: str
    ) -> Dict[str, Any]:
        """â±ï¸ Hauptfunktion: Autonome Bearbeitung mit Timeout-Handling und Latency-Tracking"""
        logger.info(f"ðŸ¤– Autonome Anfrage: {prompt[:50]}... fÃ¼r {repo_url}")
        
        # ðŸ”— URL-Validierung am Anfang
        self._validate_github_url(repo_url)
        
        # â±ï¸ Latency-Tracking Start
        start_time = time.monotonic()
        operation_metrics = {}
        
        try:
            # â±ï¸ Lock-Acquisition mit Timeout
            lock_name = f"github:{repo_url}"
            lock_start = time.monotonic()
            
            lock_acquired = await asyncio.wait_for(
                self.redis_client.acquire_lock(lock_name),
                timeout=self.timeout
            )
            operation_metrics['lock_acquisition_ms'] = round((time.monotonic() - lock_start) * 1000, 2)
            
            if not lock_acquired:
                raise ConflictError(f"Repository {repo_url} wird bereits bearbeitet")
            
            try:
                # â±ï¸ Duplicate-Check mit Timeout
                check_start = time.monotonic()
                is_duplicate = await asyncio.wait_for(
                    self.redis_client.is_duplicate_request(user_id, repo_url, prompt),
                    timeout=5
                )
                operation_metrics['duplicate_check_ms'] = round((time.monotonic() - check_start) * 1000, 2)
                
                if is_duplicate:
                    return {
                        "status": "aborted", 
                        "reason": "Duplicate request",
                        "latency_ms": self._get_latency_ms(start_time),
                        "operation_metrics": operation_metrics
                    }
                
                # Hauptverarbeitungsschritte
                process_start = time.monotonic()
                
                # Schritt 1: Analysiere Prompt und Repository
                analysis = await self.analyze_prompt_and_repo(prompt, repo_url, user_id)
                
                # Schritt 2: Erstelle Implementierungsplan
                # Annahme: risk_enum ist verfÃ¼gbar - in echtem Code anpassen
                class RiskEnum:
                    medium = "medium"
                risk_enum = RiskEnum()
                plan = await self.create_implementation_plan(analysis, risk_enum)
                
                # Schritt 3: Genehmigung einholen (wenn aktiviert)
                if self.require_approval:
                    approval = await self.request_approval(plan)
                    if not approval:
                        return {
                            "status": "aborted", 
                            "reason": "User denied approval",
                            "latency_ms": self._get_latency_ms(start_time),
                            "operation_metrics": operation_metrics
                        }
                
                # Schritt 4: FÃ¼hre Ã„nderungen aus
                changes = await self.execute_changes(plan, repo_url, user_id)
                
                # Schritt 5: Erstelle Pull Request
                pr = await self.create_pull_request(plan, changes, repo_url, user_id)
                
                # Schritt 6: Speichere im Cognee Memory
                await self.store_autonomous_action(prompt, plan, changes, pr, user_id)
                
                # â±ï¸ Hauptverarbeitungszeit berechnen
                operation_metrics['main_processing_ms'] = round((time.monotonic() - process_start) * 1000, 2)
                
                # â±ï¸ Markierung als verarbeitet mit Timeout
                mark_start = time.monotonic()
                await asyncio.wait_for(
                    self.redis_client.mark_request_processed(user_id, repo_url, prompt),
                    timeout=5
                )
                operation_metrics['mark_processed_ms'] = round((time.monotonic() - mark_start) * 1000, 2)
                
                # Erfolgreiche Antwort mit Metriken
                return {
                    "status": "success",
                    "plan": plan,
                    "changes_made": len(changes),
                    "pull_request": pr,
                    "latency_ms": self._get_latency_ms(start_time),
                    "operation_metrics": operation_metrics
                }
                
            finally:
                # â±ï¸ Lock-Release mit Timeout
                release_start = time.monotonic()
                await asyncio.wait_for(
                    self.redis_client.release_lock(lock_name),
                    timeout=5
                )
                operation_metrics['lock_release_ms'] = round((time.monotonic() - release_start) * 1000, 2)
                
        except asyncio.TimeoutError as e:
            raise TimeoutError(f"Operation timed out after {self.timeout}s: {str(e)}")
        except Exception as e:
            # Fehler mit Latency-Tracking zurÃ¼ckgeben
            raise self._enhance_error(e, start_time, operation_metrics)

    def _get_latency_ms(self, start_time: float) -> float:
        """â±ï¸ Latency in Millisekunden berechnen"""
        return round((time.monotonic() - start_time) * 1000, 2)
    
    def _enhance_error(self, error: Exception, start_time: float, metrics: Dict) -> Exception:
        """â±ï¸ Fehler mit Latency-Informationen anreichern"""
        error.latency_ms = self._get_latency_ms(start_time)
        error.operation_metrics = metrics
        return error

    async def analyze_prompt_and_repo(self, prompt: str, repo_url: str, user_id: str) -> Dict[str, Any]:
        """Analysiere was der User will und was im Repo existiert"""
        
        # Hole Repository-Context aus Cognee
        repo_context = await self.get_repo_context(repo_url, user_id)
        
        # Frage Kimi Linear nach Analyse
        analysis_prompt = f"""
        Analysiere diese Anfrage fÃ¼r ein GitHub Repository:
        
        USER ANFRAGE: {prompt}
        
        REPOSITORY Kontext:
        - Files: {len(repo_context.get('files', []))}
        - Sprachen: {repo_context.get('languages', [])}
        - Letztes Update: {repo_context.get('last_updated')}
        
        Gib zurÃ¼ck:
        1. Was der User will (klare Zusammenfassung)
        2. Welche Dateien betroffen sind
        3. Welche Ã„nderungen nÃ¶tig sind
        4. Risiko-EinschÃ¤tzung (low/medium/high)
        5. GeschÃ¤tzte KomplexitÃ¤t (1-10)
        """
        
        analysis = await self.query_kimi(analysis_prompt)
        
        return {
            "user_intent": analysis.get("intent"),
            "affected_files": analysis.get("files", []),
            "required_changes": analysis.get("changes", []),
            "risk_level": analysis.get("risk", "medium"),
            "complexity": analysis.get("complexity", 5),
            "repo_context": repo_context
        }

    async def request_approval(self, plan: Dict[str, Any]) -> bool:
        """Frage im Discord nach Genehmigung (wenn aktiviert)"""
        # TODO: Discord-Integration fÃ¼r Approval-Request
        # FÃ¼r jetzt: Simulierte Genehmigung
        logger.warning("âš ï¸  Genehmigung erforderlich - simuliert APPROVED")
        logger.info(f"Plan: {json.dumps(plan, indent=2)}")
        
        # In Produktion: Sende Discord DM/Embed und warte auf âœ…/âŒ Reaction
        return True

    async def execute_changes(self, plan: Dict[str, Any], repo_url: str, user_id: str) -> List[Dict[str, Any]]:
        """FÃ¼hre die geplanten Ã„nderungen aus"""
        
        # GitHub Client fÃ¼r Ã„nderungen
        from .github_client import GitHubClient
        github = GitHubClient()
        
        changes = []
        
        for change in plan["changes"]:
            logger.info(f"  â†’ Bearbeite: {change['file_path']} ({change['action']})")
            
            if change["action"] == "modify":
                new_content = await self.generate_code_change(change, plan["base_branch"])
            elif change["action"] == "create":
                new_content = await self.generate_new_file(change)
            elif change["action"] == "delete":
                new_content = None
            
            changes.append({
                "file_path": change["file_path"],
                "action": change["action"],
                "new_content": new_content,
                "status": "completed"
            })
        
        return changes

    async def generate_code_change(self, change: Dict[str, Any], branch: str) -> str:
        """Generiere Code-Ã„nderung mit Kimi Linear"""
        
        prompt = f"""
        Modifiziere diese Datei gemÃ¤ÃŸ Anforderung:
        
        FILE: {change['file_path']}
        REQUIREMENT: {change['description']}
        
        Falls du den aktuellen Inhalt brauchst, frage nach.
        """
        
        response = await self.query_kimi(prompt)
        return response.get("code", change.get("code_template", ""))

    async def generate_new_file(self, change: Dict[str, Any]) -> str:
        """Generiere komplett neue Datei"""
        return await self.generate_code_change(change, "main")

    async def create_pull_request(self, plan: Dict[str, Any], changes: List[Dict[str, Any]], repo_url: str, user_id: str) -> Dict[str, Any]:
        """Erstelle Pull Request mit allen Ã„nderungen"""
        
        if not os.getenv("GITHUB_AUTO_CREATE_PR", "false").lower() == "true":
            return {"status": "skipped", "message": "Auto-PR deaktiviert"}
        
        # GitHub API verwenden fÃ¼r PR-Erstellung
        # TODO: Implementiere echte PR-Erstellung
        logger.info(f"ðŸ“ PR Erstellung simuliert: {plan['branch_name']} â†’ {plan['base_branch']}")
        
        return {
            "status": "created",
            "branch": plan["branch_name"],
            "commits": len(changes),
            "url": f"{repo_url}/pull/1"  # Platzhalter
        }

    async def store_autonomous_action(self, prompt: str, plan: Dict[str, Any], changes: List[Dict[str, Any]], pr: Dict[str, Any], user_id: str):
        """Speichere autonome Aktion im Cognee Memory"""
        
        metadata = {
            "type": "autonomous_action",
            "prompt": prompt,
            "branch": plan["branch_name"],
            "changes_count": len(changes),
            "pr_url": pr.get("url"),
            "risk_level": plan["risk_level"],
            "auto_merged": False
        }
        
        payload = {
            "user_id": user_id,
            "content": f"Autonome Aktion: {prompt[:200]}...",
            "metadata": metadata
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{self.cognee_url}/memory/store",
                json=payload
            ) as resp:
                if resp.status != 201:
                    logger.warning("Speichern der autonomen Aktion fehlgeschlagen")

    async def get_repo_context(self, repo_url: str, user_id: str) -> Dict[str, Any]:
        """Hole Repository-Kontext aus Cognee"""
        # Query alle Files aus diesem Repo
        async with aiohttp.ClientSession() as session:
            async with session.get(
                f"{self.cognee_url}/memory/search",
                params={
                    "query": repo_url,
                    "user_id": user_id,
                    "limit": 50
                }
            ) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    return {
                        "files": [mem["content"][:100] for mem in data.get("memories", [])],
                        "languages": ["python"],  # Simplifiziert
                        "last_updated": "2024-01-01"
                    }
        
        return {"files": [], "languages": [], "last_updated": None}

    async def query_kimi(self, prompt: str) -> Dict[str, Any]:
        """Hilfsfunktion: Frage Kimi Linear"""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{self.kimi_url}/generate",
                json={
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                    "max_tokens": self.max_tokens
                }
            ) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    # Parse JSON aus Text-Antwort
                    try:
                        return json.loads(data["text"])
                    except:
                        return {"text": data["text"]}
        
        return {"error": "Kimi Query fehlgeschlagen"}